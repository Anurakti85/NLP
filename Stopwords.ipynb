{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Stopwords.ipynb","provenance":[],"authorship_tag":"ABX9TyN3FMyCTSDlXJ8KsOXien6d"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"e4K_E7QW77un","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1596894869188,"user_tz":-330,"elapsed":2539,"user":{"displayName":"anika sharma","photoUrl":"","userId":"09629170370723811075"}},"outputId":"c87a1aff-e221-424a-8043-12e20129224d"},"source":["#importing nltk and downloading stopwords\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","from nltk.corpus import stopwords"],"execution_count":1,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eTEl4vr48W2_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596894887948,"user_tz":-330,"elapsed":1643,"user":{"displayName":"anika sharma","photoUrl":"","userId":"09629170370723811075"}}},"source":["from nltk.tokenize import word_tokenize"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"_kF-vXdC8qSP","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596894890291,"user_tz":-330,"elapsed":1251,"user":{"displayName":"anika sharma","photoUrl":"","userId":"09629170370723811075"}}},"source":["text=\"this is a simple sentence to demonstrate stopwords in nlp\"\n","stop_words=set(stopwords.words('english'))"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"QAHuSxuBA3Dy","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596894893611,"user_tz":-330,"elapsed":1151,"user":{"displayName":"anika sharma","photoUrl":"","userId":"09629170370723811075"}}},"source":["tokenized_words=word_tokenize(text)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"gLy5EfMuBUbT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1596808956706,"user_tz":-330,"elapsed":986,"user":{"displayName":"anika sharma","photoUrl":"","userId":"09629170370723811075"}},"outputId":"07b68a46-7094-4655-fb74-30143ff544be"},"source":["cleaned_text=[]\n","for w in tokenized_words:\n","  if w not in stop_words:\n","    cleaned_text.append(w)\n","print(\"Tokens are -->\",tokenized_words) \n","print(\"\\n\")   \n","print(\"Text without stop words is -->\",cleaned_text )    "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tokens are --> ['this', 'is', 'a', 'simple', 'sentence', 'to', 'demonstrate', 'stopwords', 'in', 'nlp']\n","\n","\n","Text without stop words is --> ['simple', 'sentence', 'demonstrate', 'stopwords', 'nlp']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2EMeVRzMKfAt","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}